{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - Segmenting and Clustering Neighborhoods in Doha and Dubai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of this project is to cluster similar neighborhoods in Dubai and Doha, leveraging Foursquare location data. With the final result of the study, people that are moving from Doha to Dubai, and vice versa, will be able to easily find neighborhoods with the characteristics they are looking for in the new city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # library to handle requests\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#handle html data\n",
    "!pip install bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Webscraping Doha and Dubai Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_data = pd.DataFrame(columns=[\"City\", \"Neighborhood\", \"Latitude\", \"Longitude\"])\n",
    "\n",
    "# webscrape neighborhoods from Doha wikipedia page\n",
    "r = requests.get('https://en.wikipedia.org/wiki/List_of_communities_in_Doha')\n",
    "\n",
    "soup = BeautifulSoup(r.text.replace('\\n', ''), \"html.parser\") #replaces line break\n",
    "\n",
    "#finds the correct table based on its class\n",
    "doha_neighborhood_table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "for row in doha_neighborhood_table.find(\"tbody\").find_all(\"tr\"):\n",
    "    if not row.find_all(\"th\"): #handle data only if no table head is found\n",
    "        col = row.find_all(\"td\")\n",
    "        \n",
    "        links = col[0].find_all(\"a\", href=True)\n",
    "        \n",
    "        for link in links:\n",
    "            neighborhood = link.text\n",
    "            \n",
    "            r = requests.get('https://en.wikipedia.org' + link[\"href\"])\n",
    "            coordinates = BeautifulSoup(r.text.replace('\\n', ''), \"html.parser\").find(\"span\", {\"class\": \"geo-dec\"}).text.split()\n",
    "            latitude = coordinates[0].replace(\"째N\",\"\")\n",
    "            longitude = coordinates[1].replace(\"째E\",\"\")\n",
    "        \n",
    "            neighborhood_data = neighborhood_data.append({\"City\":\"Doha\", \"Neighborhood\":neighborhood, \"Latitude\":float(latitude), \"Longitude\":float(longitude)}, ignore_index=True)\n",
    "        \n",
    "        \n",
    "neighborhood_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscrape neighborhoods from Dubai wikipedia page\n",
    "r = requests.get('https://en.wikipedia.org/wiki/List_of_communities_in_Dubai')\n",
    "\n",
    "soup = BeautifulSoup(r.text.replace('\\n', ''), \"html.parser\") #replaces line break\n",
    "\n",
    "#finds the correct table\n",
    "dubai_neighborhood_div = soup.find(\"div\", {\"aria-labelledby\": \"Neighbourhoods_and_communities_in_Dubai\"})\n",
    "\n",
    "dubai_neighborhood_tables = dubai_neighborhood_div.find(\"table\")\n",
    "\n",
    "for item in dubai_neighborhood_tables.find(\"tbody\").find_all(\"li\", attrs = {\"class\":False}):\n",
    "    if item.find_all(\"a\"): #handle data only if there is a link to neighborhood page\n",
    "        links = item.find_all(\"a\", attrs = {\"href\":True}) \n",
    "        \n",
    "        for link in links:\n",
    "            neighborhood = link.text\n",
    "\n",
    "            r = requests.get('https://en.wikipedia.org' + link[\"href\"])\n",
    "            coordinates = BeautifulSoup(r.text.replace('\\n', ''), \"html.parser\").find(\"span\", {\"class\": \"geo-dec\"})\n",
    "            \n",
    "            if (coordinates):\n",
    "                coordinates = coordinates.text.split()\n",
    "            \n",
    "                latitude = coordinates[0].replace(\"째N\",\"\")\n",
    "                longitude = coordinates[1].replace(\"째E\",\"\")\n",
    "\n",
    "                neighborhood_data = neighborhood_data.append({\"City\":\"Dubai\", \"Neighborhood\":neighborhood, \"Latitude\":float(latitude), \"Longitude\":float(longitude)}, ignore_index=True)\n",
    "\n",
    "neighborhood_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates if they exist (e.g.: Dubai-Al Karama is listed twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_data.drop_duplicates(inplace=True)\n",
    "neighborhood_data.reset_index(inplace=True, drop=True)\n",
    "neighborhood_data.to_csv('neighborhood_data.csv')\n",
    "neighborhood_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries for geolocation and map rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge geopy --yes \n",
    "!pip install geopy\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes\n",
    "!pip install folium\n",
    "import folium # map rendering library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Maps of Doha and Dubai, marking their neighborhoods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latitude and longitude basedo on an address\n",
    "address = 'Doha, Qatar'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"doha_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "doha_latitude = location.latitude\n",
    "doha_longitude = location.longitude\n",
    "\n",
    "# create a map of Doha with the latitude and longitude\n",
    "doha_map = folium.Map(location=[doha_latitude, doha_longitude], zoom_start=11)\n",
    "\n",
    "#filter Doha neigborhoods\n",
    "doha_df = neighborhood_data.loc[neighborhood_data[\"City\"] == \"Doha\"]\n",
    "\n",
    "doha_df.dtypes\n",
    "# add markers to map\n",
    "for lat, lng, neighborhood in zip(doha_df['Latitude'], doha_df['Longitude'], doha_df['Neighborhood']):\n",
    "    label = neighborhood\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(doha_map)  \n",
    "    \n",
    "doha_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dubai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latitude and longitude basedo on an address\n",
    "address = 'Dubai, United Arab Emirates'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"dubai_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "dubai_latitude = location.latitude\n",
    "dubai_longitude = location.longitude\n",
    "\n",
    "# create a map of Dubai with the latitude and longitude\n",
    "dubai_map = folium.Map(location=[dubai_latitude, dubai_longitude], zoom_start=10\n",
    "                      )\n",
    "\n",
    "dubai_df = neighborhood_data.loc[neighborhood_data[\"City\"] == \"Dubai\"]\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, neighborhood in zip(dubai_df['Latitude'], dubai_df['Longitude'], dubai_df['Neighborhood']):\n",
    "    label = neighborhood\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(dubai_map)  \n",
    "    \n",
    "dubai_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Neighborhoods with Foursquare API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set API credentials and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = '3DJMYO2CPIQ4U5JSEGR2BGQMA44CF5RTLEPFK0NWPRBIZ5W5' \n",
    "CLIENT_SECRET = 'LO5BK0IN5QD2HD0TYIHAA2XNKX4Y5CUFADSZRVJ33400PA5F'\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to call Foursquare API for each neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(cities, names, latitudes, longitudes, radius=1000, limit=100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for city, name, lat, lng in zip(cities, names, latitudes, longitudes):\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&time=any&day=any'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            limit)\n",
    "            \n",
    "        # make the GET request\n",
    "        foursquare_return = requests.get(url).json();\n",
    "\n",
    "        try:\n",
    "            r = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        except:\n",
    "            print('ERROR: Foursquare API response: ' + str(foursquare_return))\n",
    "            return None\n",
    "        \n",
    "        if (len(r) > 10):            \n",
    "            # return relevant information for each nearby venue. This solution exclude neighborhoods from industrial areas with less the 10 venues\n",
    "            venues_list.append([(\n",
    "                city,\n",
    "                name, \n",
    "                lat, \n",
    "                lng, \n",
    "                v['venue']['name'], \n",
    "                v['venue']['location']['lat'], \n",
    "                v['venue']['location']['lng'],  \n",
    "                v['venue']['categories'][0]['name']) for v in r])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['City', 'Neighborhood',\n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude',\n",
    "                  'Venue Category']\n",
    "    \n",
    "    nearby_venues.to_csv('doha_dubai_venues.csv')\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to process all neighborhoods, and store the returned information in a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #try to avoid multiple calls to foursquare API to no exceed quota\n",
    "    doha_dubai_venues = pd.read_csv('doha_dubai_venues.csv', 0)\n",
    "    print('Finished! (CSV File)')\n",
    "except:\n",
    "    doha_dubai_venues = getNearbyVenues(cities=neighborhood_data['City'],\n",
    "                                        names=neighborhood_data['Neighborhood'],\n",
    "                                        latitudes=neighborhood_data['Latitude'],\n",
    "                                        longitudes=neighborhood_data['Longitude']\n",
    "                                          )\n",
    "    print('Finished! (Foursquare API)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doha_dubai_venues.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many venues were returned for each neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = doha_dubai_venues.groupby(['City', 'Neighborhood']).size()\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply algorithms, we must convert categorical variable into dummy/indicator variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe, converting categories into indicator variables\n",
    "# one hot encoding\n",
    "doha_dubai_onehot = pd.get_dummies(doha_dubai_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add city and neighborhood columns to dataframe\n",
    "doha_dubai_onehot['Neighborhood'] = doha_dubai_venues['Neighborhood']\n",
    "doha_dubai_onehot['City'] = doha_dubai_venues['City']\n",
    "\n",
    "doha_dubai_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doha_dubai_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doha_dubai_grouped = doha_dubai_onehot.groupby(['City', 'Neighborhood']).mean().reset_index()\n",
    "doha_dubai_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to sort venues in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[2:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store storted venues in a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['City', 'Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['City'] = doha_dubai_grouped['City']\n",
    "neighborhoods_venues_sorted['Neighborhood'] = doha_dubai_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(doha_dubai_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 2:] = return_most_common_venues(doha_dubai_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot score of diferente ks\n",
    "max_range = 10\n",
    "\n",
    "df = doha_dubai_grouped.drop(['City', 'Neighborhood'], 1)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "indices = []\n",
    "scores = []\n",
    "\n",
    "for kclusters in range(3, max_range) :\n",
    "    \n",
    "    # Run k-means clustering\n",
    "    kmeans = KMeans(n_clusters = kclusters, init = 'k-means++', random_state = 0).fit_predict(df)\n",
    "    \n",
    "    # Gets the score for the clustering operation performed\n",
    "    score = silhouette_score(df, kmeans)\n",
    "    \n",
    "    # Appending the index and score to the respective lists\n",
    "    indices.append(kclusters)\n",
    "    scores.append(score)\n",
    "    \n",
    "    #print('k=' + str(kclusters) + ' score:' + str(score))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(3, max_range), scores, 'o-')\n",
    "plt.xlabel(\"Clusters\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(np.arange(3, max_range))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kclusters = 5\n",
    "df = doha_dubai_grouped.drop(['City', 'Neighborhood'], 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(df)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Cluster's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods_venues_sorted.drop('Cluster Labels', 1, inplace=True)\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "doha_dubai_merged = neighborhoods_venues_sorted\n",
    "\n",
    "# merge dataframes to add latitude/longitude for each neighborhood\n",
    "doha_dubai_merged = doha_dubai_merged.join(neighborhood_data.set_index(['City', 'Neighborhood']), on=['City', 'Neighborhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doha_dubai_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map to analyze clusters for both cities\n",
    "map_clusters_doha = folium.Map(location=[doha_latitude, doha_longitude], zoom_start=11)\n",
    "\n",
    "doha_merged = doha_dubai_merged.loc[neighborhood_data[\"City\"] == \"Doha\"]\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(doha_merged['Latitude'], doha_merged['Longitude'], doha_merged['Neighborhood'], doha_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster)],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster)],\n",
    "        fill_opacity=0.7).add_to(map_clusters_doha)\n",
    "       \n",
    "map_clusters_doha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters_dubai = folium.Map(location=[dubai_latitude, dubai_longitude], zoom_start=11)\n",
    "\n",
    "dubai_merged = doha_dubai_merged.loc[neighborhood_data[\"City\"] == \"Dubai\"]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(dubai_merged['Latitude'], dubai_merged['Longitude'], dubai_merged['Neighborhood'], dubai_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster)],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster)],\n",
    "        fill_opacity=0.7).add_to(map_clusters_dubai)\n",
    "       \n",
    "map_clusters_dubai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighborhood distribution in clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_neighborhoods = []\n",
    "labels = []\n",
    "\n",
    "for c in range(0, kclusters-1):\n",
    "    total_dubai = len(dubai_merged.loc[dubai_merged['Cluster Labels'] == c])\n",
    "    total_doha = len(doha_merged.loc[doha_merged['Cluster Labels'] == c])\n",
    "    \n",
    "    total_neighborhoods.append((total_dubai, total_doha))\n",
    "    labels.append(str(c))   \n",
    "\n",
    "totals_df = pd.DataFrame({\n",
    "    'Dubai': [x[0] for x in total_neighborhoods],\n",
    "    'Doha': [x[1] for x in total_neighborhoods]\n",
    "}, index = labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=20, facecolor='#000000')\n",
    "totals_df.plot(kind='bar', color=['#2d1e86', '#f6962b'], rot=0, ax=ax)\n",
    "plot_conf(ax, xlbl='Cluster', ylbl='Number of neighborhoods', t='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = [0.1, 17.5, 40, 48, 52, 69, 88]\n",
    "lifespan = [2, 8, 70, 1.5, 25, 12, 28]\n",
    "index = ['snail', 'pig', 'elephant',\n",
    "         'rabbit', 'giraffe', 'coyote', 'horse']\n",
    "df = pd.DataFrame({'speed': speed,\n",
    "                   'lifespan': lifespan}, index=index)\n",
    "ax = df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Analyze each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 0]\n",
    "cluster0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 1]\n",
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 2]\n",
    "cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 3]\n",
    "cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster4 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 4]\n",
    "cluster4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster5 = doha_dubai_merged.loc[doha_dubai_merged['Cluster Labels'] == 5]\n",
    "cluster5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
